\documentclass[11pt,compress,t]{beamer}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath,amssymb,bm}
\usepackage{color,graphicx}
%% need no \usepackage{Sweave}

\definecolor{dunkelgrau}{rgb}{0.8,0.8,0.8}
\definecolor{hellgrau}{rgb}{0.95,0.95,0.95}
\newcommand{\newoperator}[3]{\newcommand*{#1}{\mathop{#2}#3}}
\newcommand{\renewoperator}[3]{\renewcommand*{#1}{\mathop{#2}#3}}

\newcommand{\va}{\bm a}
\newcommand{\ve}{\bm e}
\newcommand{\vr}{\bm r}
\newcommand{\vs}{\bm s}
\newcommand{\vu}{\bm u}
\newcommand{\vx}{\bm x}
\newcommand{\vy}{\bm y}

\newcommand{\vB}{\bm B}
\newcommand{\vE}{\bm E}
\newcommand{\vH}{\bm H}
\newcommand{\vI}{\bm I}
\newcommand{\vS}{\bm S}
\newcommand{\vV}{\bm V}
\newcommand{\vX}{\bm X}

\newcommand{\vbeta}{\bm \beta}
\newcommand{\vdelta}{\bm \delta}
\newcommand{\vomega}{\bm \omega}
\newcommand{\vtheta}{\bm \theta}

\newcommand{\vOmega}{\bm \Omega}
\newcommand{\vSigma}{\bm \Sigma}
\newcommand{\vPsi}{\bm \Psi}

%\newcommand{\E}{\text{E}}
%\newcommand{\Var}{\text{Var}}
%\newcommand{\Cov}{\text{Cov}}
\newcommand{\diag}{\text{diag}}
\newcommand{\rom}[1]{%
  \textup{\uppercase\expandafter{\romannumeral#1}}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usetheme{Z}

<<preliminaries,echo=FALSE,results=hide>>=
library("sandwich")
library("pscl")
library("lattice")
library("countreg")
library("lme4")
source("../../vignettes/sim-CL.R")
panel.xyref <- function(x, y, ...) {
  panel.abline(h = 0.95, col = 2)
  panel.xyplot(x, y, ...)  
}
options(prompt = "R> ", continue = "+   ", digits = 1)
@ 

% simulations

<<sim-01,echo=FALSE,results=hide>>=
if(file.exists("../../vignettes/sim-01.rda")) load("../../vignettes/sim-01.rda") else {
set.seed(1)
s01 <- sim(nrep = 10000, nid = 100, nround = 5,
           dist = "gaussian", rho = seq(0, 0.9, by = 0.1), xrho = 0.25,
           coef = c(0, 0.85, 0.5, 0.7), formula = response ~ x1 + x2 + x3,
           vcov = c("without", "HC0", "HC0-id", "random", "gee", "bk", "dk"),
           type = "copula")
save(s01, file = "sim-01.rda")
}
@

<<sim-02,echo=FALSE,results=hide>>=
if(file.exists("../../vignettes/sim-02.rda")) load("../../vignettes/sim-02.rda") else {
set.seed(2)
s02 <- sim(nrep = 10000, nid = 100, nround = 5,
           dist = c("gaussian", "logit", "poisson"), rho = seq(0, 0.9, by = 0.1), xrho = 0.25,
           coef = c(0, 0.85, 0, 0), formula = response ~ x1,
           vcov = c("without", "HC0", "HC0-id", "random", "gee", "bk", "dk"),
           type = "copula")
save(s02, file = "sim-02.rda")
}
@

<<sim-03,echo=FALSE,results=hide>>=
if(file.exists("../../vignettes/sim-03.rda")) load("../../vignettes/sim-03.rda") else {
set.seed(3)
s03 <- sim(nrep = 10000, nid = 100, nround = 5,
           dist = c("zerotrunc", "zip", "beta"), rho = seq(0, 0.9, by = 0.1), xrho = 0.25,
           coef = c(0, 0.85, 0, 0), formula = response ~ x1,
           vcov = c("without", "HC0", "HC0-id"),
           type = "copula")
save(s03, file = "sim-03.rda")
}
@

<<sim-04,echo=FALSE,results=hide>>=
if(file.exists("../../vignettes/sim-04.rda")) load("../../vignettes/sim-04.rda") else {
set.seed(4)
s04 <- sim(nrep = 10000, nid = c(10, seq(50, 250, by = 50)), nround = 5,
           dist = c("gaussian","poisson", "logit"), rho = 0.25, xrho = 0.25,
           coef = c(0, 0.85, 0, 0), formula = response ~ x1,
           vcov = c("HC0-id","HC1-id","HC2-id","HC3-id"),
           type = "copula")
save(s04, file = "sim-04.rda")
}
@

\title{Various Versatile Variances}
\subtitle{An Object-Oriented Implementation of Clustered Covariances in R}
\author{Susanne Berger, Nathaniel Graham, Achim Zeileis}
\URL{https://R-Forge.R-project.org/projects/sandwich/}

\begin{document}
\section{Motivation}

\begin{frame}
  \frametitle{Motivation}  

  \textbf{Goals:}
  \begin{itemize}
  \item Object-oriented implementation of clustered covariances in R.
  \item Monte Carlo simulation study to assess the performance of clustered standard errors beyond \code{lm()} and \code{glm()}.
  \end{itemize}
  
  \medskip
  
  \textbf{Strategies:}
  \begin{itemize}
  \item Account for clustered dependencies: Random effects, GEEs.
  \item Quasi-ML: Assumes a correctly specified score function but a potentially misspecified remaining likelihood.
  \end{itemize}
  
  \medskip
  
  \textbf{Special cases:} QML with sandwich covariances.
  \begin{itemize}
    \item \emph{Cross-section data}: Heteroscedasticity consistent ({HC}).
    \item \emph{Time series data}: Heteroskedasticity and autocorrelation consistent ({HAC}).
    \item \emph{Clustered/Panel data}: Panel Newey-West, Beck \& Katz, \dots
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Motivation}  
  \textbf{R package for sandwich covariances} \par\medskip
  \begin{itemize}
    \item Object-oriented implementation: \texttt{betareg}, \texttt{clm}, \texttt{crch},
\texttt{hurdle}, \texttt{lm}, \texttt{mlm}, \texttt{mlogit}, \texttt{nls}, \texttt{polr}, \texttt{survreg}, \texttt{zeroinfl} \ldots
\item \texttt{sandwich} (Zeileis, 2004, 2006).
    \item Cross-section: \texttt{vcovHC(x, \ldots)} (default: HC3)\\
      and \texttt{sandwich(x, \ldots)} (default: HC0).
    \item Time series: \texttt{vcovHAC(x, \ldots)}.\\
      Convenience functions \texttt{kernHAC(x, \ldots)} (Andrews' kernel HAC),
     \texttt{NeweyWest(x, \ldots)} (Newey-West-style HAC).
  \end{itemize} 
   \bigskip
    \textbf{Problem:} No clustered/panel covariance \emph{up to now\dots}
\end{frame}

\begin{frame}
  \frametitle{Motivation}  
  \textbf{R packages for clustered sandwich covariances} \par\medskip
  \begin{itemize}
    \item \texttt{multiwayvcov} for \texttt{lm}/\texttt{glm}(-like) objects.
    \item \texttt{plm} for \texttt{plm} objects.
    \item \texttt{geepack} for \texttt{geeglm} objects.
    \item \texttt{lfe} for \texttt{felm} objects.
    \item among others (\texttt{clusterSEs}, \texttt{clubSandwich}, \dots)
  \end{itemize}
\bigskip
  \textbf{Problem:} No object-oriented implementation \emph{up to now\dots}
\end{frame}

\begin{frame}
  \frametitle{R implementation}  
  \textbf{Building blocks provided by R package sandwich} \par\medskip
  \texttt{sandwich(x, \ldots)} calculates an estimator of the sandwich $S(\theta) = B(\theta) \cdot M(\theta) \cdot B(\theta)$. \par\medskip  
  \texttt{bread(x, \ldots)} returns the bread $B(\theta)$, typically an empirical version of the inverse Hessian. \par\medskip
  \texttt{estfun(x, \ldots)} extracts empirical estimating functions from a fitted model object \texttt{x}
  (typically $\partial \ell/\partial \theta$).\par\medskip  
  \texttt{meat(x, \ldots)}, \texttt{meatHC(x, \ldots)}, \texttt{meatHAC(x, \ldots)} return different ``flavors''
  of meat $M(\theta)$ -- relying on the model just through \texttt{estfun(x)}.\par
  \bigskip
  \textbf{Needed:} A new \texttt{meat*()} function that only extracts the \texttt{estfun()}. \par
  For the full sandwich covariance a \texttt{vcov*()} function couples the \texttt{meat*()} with the \texttt{bread()} estimate.
\end{frame}

\begin{frame}[fragile]
  \frametitle{R implementation}  
  \textbf{Clustered data:} One-, two-, and multi-way clustering.
  
  \bigskip
  
  \textbf{Idea:} Aggregate \code{estfun} within each cluster prior to computing an HC-type \code{meat}.

  \bigskip
  
  \textbf{New R function:}
\begin{verbatim}
  vcovCL(x, cluster = NULL,
    type = NULL, cadjust = TRUE, multi0 = FALSE, ...)
\end{verbatim}
  \begin{itemize}
    \item \texttt{cluster}: One or more cluster variables (cross-section if none).
    \item \texttt{type}: Type of bias correction: HC0--HC3.
    \item \texttt{cadjust}: Cluster adjustment: $\frac{G}{G-1}$.
    \item \texttt{multi0}: Multi-way clustering: HC0 estimate for final adjustment.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{R implementation}  
  \textbf{Panel data:} Driscoll \& Kraay and Panel Newey \& West covariances.
  
  \bigskip
  
  \textbf{Idea:} Sum up \code{estfun} across clusters within each time period prior to computing an HAC-type \code{meat}.

  \bigskip
  
  \textbf{New R function:}
\begin{verbatim}
  vcovPL(x, cluster = NULL, order.by = NULL,
    kernel = "Bartlett", lag = "NW1987", ...)
\end{verbatim}
  \begin{itemize}
    \item \texttt{cluster}: Cluster/group/id variable (or list of cluster and time).
    \item \texttt{order.by}: Time variable.
    \item \texttt{kernel}: Kernel functions: ``Bartlett'', ``truncated'', ``Tukey-Hanning'', ``quadratic spectral''.
    \item \texttt{lag}: Lag length: ``NW1987'', ``NW1994'', ``max'' (or ``P2009'').
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{R implementation}  
  \textbf{Panel data:} Panel-corrected covariances (Beck and Katz, 1995).
  
  \bigskip
  
  \textbf{Idea:} Outer product of (working) residuals (\code{estfun/model.matrix}) within each cluster, each component expanded with an identity matrix of size \code{length(order.by)}.

  \bigskip
  
  \textbf{New R function:}
\begin{verbatim}
  vcovPC(x, cluster = NULL, order.by = NULL,
    subsample = FALSE, ...)
\end{verbatim}
  \begin{itemize}
    \item \texttt{cluster}: Cluster/group/id variable (or list of cluster and time).
    \item \texttt{order.by}: Time variable.
    \item \texttt{subsample}: Pairwise balanced sample or balanced subset.
  \end{itemize}
\end{frame}

\begin{frame}[containsverbatim]
  \frametitle{Innovation data}
  \textbf{Motivation:} Applicability of clustered covariances to models beyond \texttt{lm()} or \texttt{glm()}. 
  
  \bigskip
  
  \textbf{Data:} Aghion et al.\ (2013) analyze the effect of (the share of stock owned by) institutions on innovation (cite-weighted patents).
  
  \bigskip
  
  \textbf{Original analysis by Aghion et al. (2013):} Quasi-Poisson with clustered standard errors.
  
  \bigskip
  
  \textbf{Reanalysis by Berger et al. (2017):} Clustered covariances were provided for negative binomial hurdle models. 
  \nocite{vcov:Berger+Stocker+Zeileis:2016}
  \nocite{vcov:Aghion+VanReenen+ZIngales:2013}
\end{frame}

\begin{frame}[containsverbatim]
  \frametitle{Innovation data}
  \textbf{Data and model fit:}
  
  \medskip
  
<<example-innovation-01,echo=TRUE>>= 
data(InstInnovation, package = "sandwich")
library("countreg")
m <- hurdle(
  cites ~ institutions + log(capital/employment) + log(sales),
  data = InstInnovation,
  dist = "negbin", zero.dist = "negbin", separate = FALSE)
@

 \medskip
 
\textbf{Customizing covariances:} ``Standard'', basic and clustered covariances. 

 \medskip
<<example-innovation-02,echo=TRUE>>= 
library("sandwich")
vc <- list(
  "standard" = vcov(m),
  "basic" = sandwich(m),
  "CL-1" = vcovCL(m, cluster = InstInnovation$company)
)
@
\end{frame}

\begin{frame}[containsverbatim] 
\frametitle{Innovation data}
<<example-innovation-03,echo=TRUE>>= 
sapply(vc, function(x) sqrt(diag(x)))
@

\bigskip

For clustered data, standard errors can overstate estimator precision.

\bigskip

Compared to \code{basic}, \code{CL-1} standard errors are scaled up by factors between $1.47$ and $2$.
\end{frame}

\begin{frame}
  \frametitle{Simulation}  
  \textbf{Response:} $y_{ig} \sim F(\mu_{ig})$. $F =$ Normal/Gaussian, binomial (logit), Poisson, zero-truncated Poisson, beta, zero-inflated Poisson (ZIP).
  
  \bigskip
  
  \textbf{Regression:} $h(\mu_{ig}) = 0 + 0.85 \cdot x_{ig}$.

  \bigskip

  \textbf{Correlations:}
  \begin{itemize}
    \item Cluster correlation $\rho$ for response $y_{ig}$ (via Gaussian copula).
    \item Regressor $x_{ig}$ has within cluster correlation $0.25$.
  \end{itemize}

  \bigskip

  \textbf{Setup:} 10,000 replications, 500 observations (5 obs.\ per 100 clusters).

  \bigskip

  \textbf{Outcome:} Empirical coverage of $95\%$ confidence intervals for slope.
  %% \begin{itemize}
  %%   \item $<0.95$ indicates downward bias (toward Type I errors).
  %%   \item $>0.95$ indicates a conservative (Type II error) bias.
  %% \end{itemize}
\end{frame}

\begin{frame}[containsverbatim] 
\frametitle{Simulation}

\hspace*{-0.5cm}%
\setkeys{Gin}{width=1.1\textwidth}%
<<sim-02-figure,echo=FALSE,fig=TRUE,height=5,width=10>>=
my.settings <- canonical.theme(color = TRUE)
my.settings[["strip.background"]]$col <- "gray"
my.settings[["strip.border"]]$col <- "black"
my.settings[["superpose.line"]]$lwd <- 1
levels(s02$dist) <- c("gaussian", "binomial(logit)", "poisson")
levels(s02$vcov)[c(5,2,1,7,4,6,3)] <- c("CL-0", "PL", "PC", "standard", "basic", "random", "gee")
s02$vcov <- factor(s02$vcov, levels(s02$vcov)[c(5,2,1,7,4,6,3)])
my.settings[["superpose.line"]]$col <- c("#377eb8", "green","#006400", "#ff7f00", "#f781bf", "#984ea3", "#e41a1c")
my.settings[["superpose.symbol"]]$col <- c("#377eb8", "green","#006400", "#ff7f00", "#f781bf", "#984ea3", "#e41a1c")
my.settings[["superpose.symbol"]]$pch <- c(rep(1,3), rep(2,2), rep(3,2))
xyplot(coverage ~ rho | dist, groups = ~ factor(vcov),
  data = s02, subset = par != "(Intercept)",
  ylim = c(0.5, 1),
  type = "b", xlab = expression(rho), ylab = "coverage",
  auto.key = list(columns = 3),
  par.strip.text = list(col = "black"), par.settings = my.settings,
  panel = panel.xyref)
@  

\end{frame}

\begin{frame}[containsverbatim] 
\frametitle{Simulation}

\hspace*{-0.5cm}%
\setkeys{Gin}{width=1.1\textwidth}%
<<sim-03-figure,echo=FALSE,fig=TRUE,height=5,width=10>>=
panel.xyref <- function(x, y, ...) {
  panel.abline(h = 0.95, col = 2)
  panel.xyplot(x, y, ...)  
}
options(prompt = "R> ", continue = "+   ", digits = 2)
s03 <- na.omit(s03)
my.settings <- canonical.theme(color = TRUE)
my.settings[["strip.background"]]$col <- "gray"
my.settings[["strip.border"]]$col <- "black"
my.settings[["superpose.line"]]$lwd <- 1
levels(s03$vcov)[c(2,3,1)]  <- c("CL-0", "standard", "basic")
levels(s03$dist)[c(1,2,3)] <- c("betareg", "zerotrunc", "zeroinfl")
s03$vcov <- factor(s03$vcov, levels(s03$vcov)[c(2,3,1)])
my.settings[["superpose.line"]]$col <- c("#377eb8", "#ff7f00", "#f781bf")
my.settings[["superpose.symbol"]]$col <- c("#377eb8", "#ff7f00", "#f781bf")
my.settings[["superpose.symbol"]]$pch <- c(1, rep(2,2))
xyplot(coverage ~ rho | dist, groups = ~ factor(vcov),
  data = s03, subset = par != "(Intercept)",
  ylim = c(0.8, 1),
  type = "b", xlab = expression(rho), ylab = "coverage",
  auto.key = list(columns = 2),
  par.strip.text = list(col = "black"), par.settings = my.settings,
  panel = panel.xyref)
@ 


\end{frame}

\begin{frame}[allowframebreaks]
  \frametitle{References}
{\small
  \textbf{On R-Forge:} \url{https://R-Forge.R-project.org/projects/sandwich/}

  \bigskip
  
  \textbf{New manuscript:} \texttt{vignette("sandwich-CL", package = "sandwich")}

}

\bigskip

{\scriptsize
 Aghion P, Van Reenen J, Zingales L (2013).
  Innovation and Institutional Ownership.
  \emph{The American Economic Review}, $\bold{103}(1)$, 277--304.
  \doi{10.1257/aer.103.1.277}

\medskip

Berger S, Stocker H, Zeileis A (2017).
  Innovation and Institutional Ownership Revisited: An Empirical Investigation with Count Data Models.
  \emph{Empirical Economics}, $\bold{52}(4)$,
  1675--1688
  \doi{10.1007/s00181-016-1118-0}

\medskip

Cameron AC, Gelbach JB, Miller DL (2011).
  Robust Inference With Multiway Clustering,
  \emph{Journal of Business \& Ecomomic Statistics}, $\bold{29}(2)$,
  238--249.
  \doi{10.1198/jbes.2010.07136}  

\medskip

Cameron AC,  Miller DL (2015).
  A Practitioner's Guide to Cluster-Robust Inference,
  \emph{Journal of Human Resources}, $\bold{50}(2)$,
  317--372.

%% \medskip  
%% 
%% McCaffrey DF, Bell RM (2002).
%%   Bias Reduction in Standard Errors for Linear Regression with Multi-Stage Samples,
%%   \emph{Survey Methodology}, $\bold{28}(2)$, 169--181.

\medskip

Zeileis A (2004).
  Econometric Computing with HC and HAC Covariance Matrix Estimator,
  \emph{Journal of Statistical Software}, $\bold{11}(10)$, 1--17.
  \doi{10.18637/jss.v011.i10}
  \par\medskip

Zeileis A (2006).
  Object-Oriented Computation of Sandwich Estimators,
  \emph{Journal of Statistical Software}, $\bold{16}(9)$, 1--16.
  \doi{10.18637/jss.v016.i09}
 
}
\end{frame}

\begin{frame}[containsverbatim] 
\frametitle{Simulation}  
F = Gaussian with correlated, clustered, and uncorrelated regressors.

\bigskip

\hspace*{-0.5cm}%
\setkeys{Gin}{width=1.1\textwidth}%
<<sim-01-figure,echo=FALSE,fig=TRUE,height=5,width=10>>=
my.settings <- canonical.theme(color = TRUE)
my.settings[["strip.background"]]$col <- "gray"
my.settings[["strip.border"]]$col <- "black"
my.settings[["superpose.line"]]$lwd <- 1
levels(s01$vcov)[c(5,2,1,7,4,6,3)] <- c("CL-0", "PL", "PC", "standard", "basic", "random", "gee")
s01$vcov <- factor(s01$vcov, levels(s01$vcov)[c(5,2,1,7,4,6,3)])
my.settings[["superpose.line"]]$col <- c("#377eb8", "green","#006400", "#ff7f00", "#f781bf", "#984ea3", "#e41a1c")
my.settings[["superpose.symbol"]]$col <- c("#377eb8", "green","#006400", "#ff7f00", "#f781bf", "#984ea3", "#e41a1c")
my.settings[["superpose.symbol"]]$pch <- c(rep(1,3), rep(2,2), rep(3,2))
xyplot(coverage ~ rho | par, groups = ~ factor(vcov),
  data = s01, subset = par != "(Intercept)",
  ylim = c(0, 1),
  type = "b", xlab = expression(rho), ylab = "coverage",
  auto.key = list(columns = 3),
  par.strip.text = list(col = "black"), par.settings = my.settings,
  panel = panel.xyref)
@  
\end{frame}

\begin{frame}[containsverbatim] 
\frametitle{Simulation}
Increase number of clusters (observations per cluster constant).

\bigskip

\hspace*{-0.5cm}%
\setkeys{Gin}{width=1.1\textwidth}%
<<sim-04-figure,echo=FALSE,fig=TRUE,height=5,width=10>>=
my.settings <- canonical.theme(color = TRUE)
my.settings[["strip.background"]]$col <- "gray"
my.settings[["strip.border"]]$col <- "black"
my.settings[["superpose.line"]]$lwd <- 1
levels(s04$vcov)[c(1:4)] <- c("CL-0", "CL-1", "CL-2", "CL-3")
s04$vcov <- factor(s04$vcov, levels(s04$vcov)[c(1:4)])
levels(s04$dist)[c(1:3)] <- c("gaussian", "binomial(logit)", "poisson")
my.settings[["superpose.line"]]$col <- c("#377eb8", "#00E5EE", "#e41a1c", "#4daf4a")
my.settings[["superpose.symbol"]]$col <- c("#377eb8", "#00E5EE","#e41a1c", "#4daf4a")
xyplot(coverage ~ nid | dist, groups = ~ factor(vcov),
  data = na.omit(s04), subset = par != "(Intercept)",
  type = "b", xlab = "G", ylab = "coverage",
  auto.key = list(columns = 2),
  par.strip.text = list(col = "black"), par.settings = my.settings,
  panel = panel.xyref)
@
\end{frame}



\end{document}

